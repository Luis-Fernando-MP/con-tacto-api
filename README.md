<p align="center" style="display: flex; gap: 10px; flex-wrap: wrap; justify-content: center">
  <img src="./background.png" alt="Swagger API Demo"  style="border-radius: 12px; max-height: 300px; width: auto">
  <img src="./esp32.jpg" alt="Swagger API Demo" width="80%" style="border-radius: 12px; max-height: 300px; width: auto">
</p>

<p align="center">
  <img src="https://img.shields.io/badge/-NestJS-grayk?style=flat&logo=nestjs&logoColor=E0234E" alt="NestJS" />
  <img src="https://img.shields.io/badge/Braille%20SP39-Hardware-blueviolet?style=flat&logo=raspberrypi&logoColor=white" alt="Braille SP39" />
  <img src="https://img.shields.io/badge/AI-Deepseek-green?style=flat&logo=openai&logoColor=white" alt="AI" />
  <img src="https://img.shields.io/badge/TTS-WAV-orange?style=flat&logo=soundcloud&logoColor=white" alt="TTS" />
</p>

---

# üåü Con-tacto API ‚Äì Backend

**Con-tacto** es una respuesta innovadora en desarrollo, que busca que las personas con DSI puedan tocar el mundo a trav√©s del braille, combinamos un hardware t√°ctil con inteligencia artificial y s√≠ntesis de voz. A trav√©s del m√≥dulo SP39, cada pulsaci√≥n en braille se convierte en una respuesta de audio, abriendo paso al di√°logo con familiares, amigos y asistentes naturales o virtuales.

> **Este repositorio es el backend de Con-tacto.**  
> El hardware SP39 detecta pulsaciones en braille y las traduce a texto.  
> La API recibe ese texto, lo procesa con IA, lo convierte a audio (WAV) mediante TTS y lo retorna al usuario.

---

## ¬øQu√© hace Con-tacto?

- **Entrada:** El m√≥dulo SP39 (hardware) detecta pulsaciones en braille y las traduce a texto.
- **Comunicaci√≥n:** El texto llega a esta API (NestJS), que lo procesa y lo env√≠a a un modelo de IA.
- **Respuesta:** La IA genera una respuesta contextual.
- **Audio:** La respuesta se sintetiza a voz (WAV) usando TTS y se retorna al usuario.
- **Interacci√≥n:** Permite el di√°logo entre usuarios, familiares, amigos y asistentes (naturales o virtuales).

---

## üß© Componentes principales

- **API REST & WebSocket:** Endpoints y canales en tiempo real para interacci√≥n usuario-tutor.
- **M√≥dulo de Chat:** Env√≠a mensajes y recibe respuestas de IA, convertidas a audio.
- **M√≥dulo de Historias:** Genera historias/podcasts personalizados con IA y los convierte a audio.
- **S√≠ntesis de Voz (TTS):** Modelos multiling√ºes y configurables ([`VoiceModels`](src/tts/VoiceModels.ts)), ajustando volumen, tono y velocidad.
- **Swagger:** Documentaci√≥n interactiva en `/api`.

---

## üóÇÔ∏è Estructura del proyecto

- [`src/app.module.ts`](src/app.module.ts): M√≥dulo ra√≠z que integra los subm√≥dulos principales.
- [`src/chat/`](src/chat/): L√≥gica de chat, controladores y DTOs para mensajes y respuestas de voz.
- [`src/story/`](src/story/): Generaci√≥n de historias/podcasts personalizados.
- [`src/socket/`](src/socket/): Comunicaci√≥n en tiempo real v√≠a WebSocket.
- [`src/tts/`](src/tts/): Modelos y servicio de s√≠ntesis de voz.
- [`src/ai/`](src/ai/): L√≥gica de IA para generaci√≥n de texto y prompts personalizados.

---

## Instalaci√≥n y uso

### Clone el repositorio

```shell
git clone git@github.com:Luis-Fernando-MP/con-tacto-api.git
```

### üöÄ Instale y ejecute

```shell
pnpm install
pnpm run start
```

- Accede a la documentaci√≥n en: http://127.0.0.1:3000/api
- El frontend de ejemplo est√° en [`./index.html`](index.html) (interacci√≥n usuario-tutor en tiempo real).

# Recursos √∫tiles

- [NestJS Documentation](https://docs.nestjs.com/)
- [Con-tacto Hardware SP39](https://github.com/tuusuario/con-tacto) <!-- cambia por tu URL real -->
- [@andresaya/edge-tts](https://www.npmjs.com/package/@andresaya/edge-tts)

# üìù Licencia

Nest est√° bajo licencia [MIT](https://opensource.org/licenses/MIT).
